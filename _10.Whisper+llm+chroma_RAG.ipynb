{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463f25b8-ac50-4738-9735-8871ea94d599",
   "metadata": {},
   "source": [
    "# Chat with Audio Locally: A Guide to RAG with Whisper, Ollama, and Chromadb(can also use FAISS)\n",
    "Features\n",
    "1. Featured timestamp attached detection, for timestamp speech slice trace\n",
    "2. manual cosine similarity search for audio\n",
    "3. vector store similarity fetch docs for QA\n",
    "\n",
    "Inspired by: \n",
    "* https://medium.com/@ingridwickstevens/chat-with-your-audio-locally-a-guide-to-rag-with-whisper-ollama-and-faiss-6656b0b40a68\n",
    "* https://www.youtube.com/watch?v=TdMkKvzPe3E\n",
    "\n",
    "### 1. Transcribe audio to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065a090c-2027-4629-8700-864c918c87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from progress_bar_decorator import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "991d84e7-a994-4f71-a306-e68c45b19b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mps', torch.float16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_mps = torch.backends.mps.is_available()\n",
    "has_cuda = torch.cuda.is_available()\n",
    "device = \"mps\" if has_mps else \"cuda\" if has_cuda else \"cpu\"\n",
    "torch_dtype = torch.float16 if has_mps else torch.float32\n",
    "device, torch_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60f8690-9390-4ae8-bed4-4ea3431cfb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"openai/whisper-large-v3\"\n",
    "# model_id = \"openai/whisper-medium\"\n",
    "\n",
    "hf_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch_dtype, \n",
    "    low_cpu_mem_usage=True, \n",
    "    use_safetensors=True,\n",
    "    cache_dir='/Users/leon/Documents/03.LLM/whisper/models/'\n",
    ").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67bcae50-ddcd-4dcb-9f73-3bfe2473f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=hf_model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,  # 128\n",
    "    chunk_length_s=64,   # 30 \n",
    "    batch_size=24,       # 16  \n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    ignore_warning=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b337125-6f4f-4f86-b4e1-99b79aafdeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:58<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 14.6 s, total: 1min 20s\n",
      "Wall time: 2min 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "audio_file = './whisper/audio/Pinf_meeting.mp3'\n",
    "\n",
    "@progress_bar(expected_time=180)\n",
    "def transcribe():\n",
    "    result = pipe(\n",
    "        audio_file, \n",
    "        generate_kwargs={\"language\": \"Mandarin\",},\n",
    "        return_timestamps=True,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "result = transcribe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e237b25-c7cb-415a-8ac5-e35ca1a3c1b8",
   "metadata": {},
   "source": [
    "128, 64, 24\n",
    "CPU times: user 35.9 s, sys: 14.6 s, total: 50.4 s\n",
    "Wall time: 2min 53s\n",
    "++++++++++++++++++++++++\n",
    "128, 64, 20\n",
    "CPU times: user 59 s, sys: 12.9 s, total: 1min 11s\n",
    "Wall time: 2min 52s\n",
    "+++++++++++++++++++++++\n",
    "128, 60, 32\n",
    "CPU times: user 43.2 s, sys: 44.5 s, total: 1min 27s\n",
    "Wall time: 5min 7s\n",
    "++++++++++++++++++++++++\n",
    "128, 60, 16\n",
    "CPU times: user 1min, sys: 13.9 s, total: 1min 14s\n",
    "Wall time: 2min 57s\n",
    "+++++++++++++++++++++++++\n",
    "256, 60, 16\n",
    "CPU times: user 1min 35s, sys: 32.7 s, total: 2min 7s\n",
    "Wall time: 4min 58s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da526316-29eb-4158-a1a4-ebdfe1a952a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de65e382-b524-4436-a863-c0cf1f49cb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.84)</td>\n",
       "      <td>好的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.84, 3.38)</td>\n",
       "      <td>看得到</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3.38, 5.24)</td>\n",
       "      <td>OK 看得到</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(5.24, 6.58)</td>\n",
       "      <td>首先</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(6.58, 9.3)</td>\n",
       "      <td>欢迎大家</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>(3689.05, 3723.06)</td>\n",
       "      <td>可以给到大家可能会有一个下一次我们再来review的一个action item然后那么咱们今...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>(3723.06, 3725.16)</td>\n",
       "      <td>然后谢谢大家的时间</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>(3725.16, 3727.64)</td>\n",
       "      <td>好谢谢大家</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>(3727.64, 3728.34)</td>\n",
       "      <td>谢谢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>(3728.34, 3729.4)</td>\n",
       "      <td>拜拜</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp                                               text\n",
       "0           (0.0, 1.84)                                                 好的\n",
       "1          (1.84, 3.38)                                                看得到\n",
       "2          (3.38, 5.24)                                             OK 看得到\n",
       "3          (5.24, 6.58)                                                 首先\n",
       "4           (6.58, 9.3)                                               欢迎大家\n",
       "..                  ...                                                ...\n",
       "615  (3689.05, 3723.06)  可以给到大家可能会有一个下一次我们再来review的一个action item然后那么咱们今...\n",
       "616  (3723.06, 3725.16)                                          然后谢谢大家的时间\n",
       "617  (3725.16, 3727.64)                                              好谢谢大家\n",
       "618  (3727.64, 3728.34)                                                 谢谢\n",
       "619   (3728.34, 3729.4)                                                 拜拜\n",
       "\n",
       "[620 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_transcribe = pd.DataFrame(result['chunks'])\n",
    "df_transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e2bee58-55f1-4288-8480-9b543c4aa3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse timestamp function\n",
    "def parse_audio_slice_timestamp(time_tuple):\n",
    "    time_list = list(time_tuple)\n",
    "    return time_list[0], time_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19dd35b9-f0d2-482e-887a-33255f5873b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.84)</td>\n",
       "      <td>好的</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.84, 3.38)</td>\n",
       "      <td>看得到</td>\n",
       "      <td>1.84</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3.38, 5.24)</td>\n",
       "      <td>OK 看得到</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(5.24, 6.58)</td>\n",
       "      <td>首先</td>\n",
       "      <td>5.24</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(6.58, 9.3)</td>\n",
       "      <td>欢迎大家</td>\n",
       "      <td>6.58</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp    text  start   end\n",
       "0   (0.0, 1.84)      好的   0.00  1.84\n",
       "1  (1.84, 3.38)     看得到   1.84  3.38\n",
       "2  (3.38, 5.24)  OK 看得到   3.38  5.24\n",
       "3  (5.24, 6.58)      首先   5.24  6.58\n",
       "4   (6.58, 9.3)    欢迎大家   6.58  9.30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_filename = './whisper/transcribe/huggingface_Pinf_meeting.csv'\n",
    "\n",
    "df_transcribe.loc[:, 'start'] = df_transcribe['timestamp'].apply(lambda x: list(x)[0])\n",
    "df_transcribe.loc[:, 'end'] = df_transcribe['timestamp'].apply(lambda x: list(x)[1])\n",
    "df_transcribe.to_csv(transcribe_filename, index=False)\n",
    "df_transcribe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0aa8964-bf8a-4f2c-8048-7ec926bf1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe_text_filename = './whisper/transcribe/Pinf_meeting.txt'\n",
    "\n",
    "with open(transcribe_text_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b98f90-7864-4847-aad6-61aaef645286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of this audio file 62.24 minutes\n",
      "Text: 可能要更多的考虑到\n",
      "Playing audio slice start from 14.535166666666667m to 14.565499999999998m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/lv/4kql5s856s56ycnzm1ly8y0m0000gn/T/tmpl14tettp.wav':\n",
      "  Duration: 00:00:01.82, bitrate: 768 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 1 channels, s16, 768 kb/s\n",
      "   1.77 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "sound = AudioSegment.from_file(audio_file)\n",
    "print(f'Length of this audio file {round(len(sound)/1000/60, 2)} minutes')\n",
    "\n",
    "row = df_transcribe.iloc[150, :]\n",
    "print('Text:', row['text'])\n",
    "print('Playing audio slice start from {}m to {}m'.format(row['start']/60, row['end']/60))\n",
    "\n",
    "# audio timestamp in ms, hence times 1000\n",
    "play(sound[row['start']*1000: row['end']*1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3de934c-6d6d-4cc6-9181-a76eceac8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play(sound[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa7dad3-b2af-4461-891e-306398e36c73",
   "metadata": {},
   "source": [
    "### 2. Tokenize and embed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d542652-17a4-45d5-8866-79af272f24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef560c2c-8c40-47c9-9cb9-e4d2bc521bfd",
   "metadata": {},
   "source": [
    "#### 2.1 Direct embedding against audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c517c7f-6a5d-4869-9adb-68354c5bc60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.84)</td>\n",
       "      <td>好的</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.84, 3.38)</td>\n",
       "      <td>看得到</td>\n",
       "      <td>1.84</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3.38, 5.24)</td>\n",
       "      <td>OK 看得到</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(5.24, 6.58)</td>\n",
       "      <td>首先</td>\n",
       "      <td>5.24</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(6.58, 9.3)</td>\n",
       "      <td>欢迎大家</td>\n",
       "      <td>6.58</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp    text  start   end\n",
       "0   (0.0, 1.84)      好的   0.00  1.84\n",
       "1  (1.84, 3.38)     看得到   1.84  3.38\n",
       "2  (3.38, 5.24)  OK 看得到   3.38  5.24\n",
       "3  (5.24, 6.58)      首先   5.24  6.58\n",
       "4   (6.58, 9.3)    欢迎大家   6.58  9.30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_filename = 'huggingface_Pinf_meeting.csv'\n",
    "\n",
    "df_embed = pd.read_csv(transcribe_filename)\n",
    "df_embed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db490dc",
   "metadata": {},
   "source": [
    "##### Choose embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11076c81-2a03-436b-8949-bae35993900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings, SentenceTransformerEmbeddings\n",
    "# embeddings = OllamaEmbeddings(model='llama2-chinese:latest')\n",
    "# embeddings = OllamaEmbeddings(model='mxbai-embed-large:latest')\n",
    "# embeddings = OllamaEmbeddings(model='nomic-embed-text:latest')\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name='BAAI/bge-large-zh-v1.5', \n",
    "    cache_folder='/Users/leon/Documents/03.LLM/embedding_models'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0827d497-b942-405d-82db-5a9acd11c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda function to embed audio text\n",
    "add_embed = lambda x: embeddings.embed_query(x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b81b22-7fa4-4e9a-94cb-874089764d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similiarity search function\n",
    "import numpy as np\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94363d13-969c-4870-a87c-707bc7cec4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 1.64 s, total: 15.2 s\n",
      "Wall time: 16.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.84)</td>\n",
       "      <td>好的</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.84</td>\n",
       "      <td>[0.028062285855412483, 0.03217782825231552, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.84, 3.38)</td>\n",
       "      <td>看得到</td>\n",
       "      <td>1.84</td>\n",
       "      <td>3.38</td>\n",
       "      <td>[0.058578137308359146, -0.010690493509173393, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3.38, 5.24)</td>\n",
       "      <td>OK 看得到</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.24</td>\n",
       "      <td>[0.06891053169965744, -0.022434687241911888, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(5.24, 6.58)</td>\n",
       "      <td>首先</td>\n",
       "      <td>5.24</td>\n",
       "      <td>6.58</td>\n",
       "      <td>[-0.021473880857229233, 0.016622141003608704, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(6.58, 9.3)</td>\n",
       "      <td>欢迎大家</td>\n",
       "      <td>6.58</td>\n",
       "      <td>9.30</td>\n",
       "      <td>[0.04682959243655205, -0.011324206367135048, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp    text  start   end  \\\n",
       "0   (0.0, 1.84)      好的   0.00  1.84   \n",
       "1  (1.84, 3.38)     看得到   1.84  3.38   \n",
       "2  (3.38, 5.24)  OK 看得到   3.38  5.24   \n",
       "3  (5.24, 6.58)      首先   5.24  6.58   \n",
       "4   (6.58, 9.3)    欢迎大家   6.58  9.30   \n",
       "\n",
       "                                          text_embed  \n",
       "0  [0.028062285855412483, 0.03217782825231552, -0...  \n",
       "1  [0.058578137308359146, -0.010690493509173393, ...  \n",
       "2  [0.06891053169965744, -0.022434687241911888, 0...  \n",
       "3  [-0.021473880857229233, 0.016622141003608704, ...  \n",
       "4  [0.04682959243655205, -0.011324206367135048, -...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_embed.loc[:, 'text_embed'] = df_embed.apply(add_embed, axis=1)\n",
    "df_embed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b2b6d35-f1d0-4bed-ab19-1a799e58a5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check embeded vector length\n",
    "len(df_embed['text_embed'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64667d07-b2af-4657-a3b4-dd7c99067f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give your search query\n",
    "search_term = '这个月的performance rating是什么'\n",
    "search_term_embed = embeddings.embed_query(search_term)\n",
    "len(search_term_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "206c330a-24ee-401a-8c1c-f47a39a7443c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_embed</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(53.47, 55.97)</td>\n",
       "      <td>然后我们对整个的这个performance rating</td>\n",
       "      <td>53.47</td>\n",
       "      <td>55.97</td>\n",
       "      <td>[0.03247657045722008, 0.02801506407558918, -0....</td>\n",
       "      <td>0.628719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>(485.77, 488.01)</td>\n",
       "      <td>关于performance monitor的一项要求</td>\n",
       "      <td>485.77</td>\n",
       "      <td>488.01</td>\n",
       "      <td>[0.022812873125076294, -0.010444370098412037, ...</td>\n",
       "      <td>0.579513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(186.35, 189.15)</td>\n",
       "      <td>performance monitoring的维度上</td>\n",
       "      <td>186.35</td>\n",
       "      <td>189.15</td>\n",
       "      <td>[0.023510172963142395, 0.008555696345865726, -...</td>\n",
       "      <td>0.577905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp                          text   start     end  \\\n",
       "15    (53.47, 55.97)  然后我们对整个的这个performance rating   53.47   55.97   \n",
       "87  (485.77, 488.01)    关于performance monitor的一项要求  485.77  488.01   \n",
       "39  (186.35, 189.15)    performance monitoring的维度上  186.35  189.15   \n",
       "\n",
       "                                           text_embed  cosine_similarity  \n",
       "15  [0.03247657045722008, 0.02801506407558918, -0....           0.628719  \n",
       "87  [0.022812873125076294, -0.010444370098412037, ...           0.579513  \n",
       "39  [0.023510172963142395, 0.008555696345865726, -...           0.577905  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct similiarity and sorting\n",
    "df_embed.loc[:, 'cosine_similarity'] = df_embed['text_embed'].apply(lambda x: cosine_similarity(x, search_term_embed))\n",
    "df_sorted = df_embed.sort_values(by='cosine_similarity', ascending=False)\n",
    "df_sorted.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce8a8007-a25d-4fd4-b56a-2f9201f06fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/lv/4kql5s856s56ycnzm1ly8y0m0000gn/T/tmp2q5657_a.wav':\n",
      "  Duration: 00:00:02.50, bitrate: 768 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 1 channels, s16, 768 kb/s\n",
      "   2.42 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/lv/4kql5s856s56ycnzm1ly8y0m0000gn/T/tmpgvuahzt7.wav':\n",
      "  Duration: 00:00:02.24, bitrate: 768 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 1 channels, s16, 768 kb/s\n",
      "   2.16 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/lv/4kql5s856s56ycnzm1ly8y0m0000gn/T/tmp5bqof1c6.wav':\n",
      "  Duration: 00:00:02.80, bitrate: 768 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 1 channels, s16, 768 kb/s\n",
      "   2.68 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/lv/4kql5s856s56ycnzm1ly8y0m0000gn/T/tmp1u5hoylt.wav':\n",
      "  Duration: 00:00:03.02, bitrate: 768 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 1 channels, s16, 768 kb/s\n",
      "   2.95 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/lv/4kql5s856s56ycnzm1ly8y0m0000gn/T/tmppwfo4p7t.wav':\n",
      "  Duration: 00:00:33.36, bitrate: 768 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 1 channels, s16, 768 kb/s\n",
      "  33.22 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# playsound for top 5 ranking\n",
    "for index, row in df_sorted.iloc[:5].iterrows():\n",
    "    play(sound[row.start*1000: row.end*1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391cd43a-e30c-450e-a4d9-384b3ca02870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "333a446f-82e8-4cdd-b236-2ce12c36a404",
   "metadata": {},
   "source": [
    "#### 2.2 Embedding for LLM-based RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a560762d-6c9c-455a-8f92-3fcd24bb1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define text to split\n",
    "with open(transcribe_text_filename, 'r') as f:\n",
    "    transcribe_text = f.read()\n",
    "\n",
    "# split the text into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = splitter.split_text(transcribe_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ca2558e-198e-4bc3-b408-65cfa395f8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,\n",
       " 'Launch是在二三年的十二月份它主要的一个开发功能是包括Pipeline管理工作管理和客户管理等等它风险是目前进入上是没有已经实施已经暂停那现在业务正在探索其他的解决方案来降低成本那一旦就是确定了解决方案IT工作就会恢复那后期如果有最新的进展下次会议会同步给大家就是最新的Money Poly的一个最新状况最后一个是关于审测审测就是说它的SDK定到iHub的数据传输的实施也是正在进行中以上是关于聘服的项目进展情况谢谢大家谢谢上门包括Leo还有Jene如果比如说你们对哪个项目比较关注或者说你觉得这个项目可能比较重要的话在后面比如说以后汇报或者说更近的时候就会更多的去帮大家去这个project list对就是可能先先听一下大家的反馈吧这对这个项目当然我们之前提到的就是把这些项目我们开成两页包括这个信息的规范我们这个下次一定会改进好的好')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts), texts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3feb97d0-35df-4ab6-9ac4-0acfb6ad01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# speech_vector.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fba2f7fc-2465-42d9-bdc5-6aad85047dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector store using Chroma\n",
    "speech_vector = Chroma.from_texts(\n",
    "    texts, \n",
    "    embedding=embeddings, \n",
    "    metadatas=[{'source': str(i)} for i in range(len(texts))],\n",
    "    collection_name='speech-rag',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5d603-3ff0-4e6e-85a9-f58c2fb3c85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccd20b5a-345a-4118-b5af-cab4ce9373a5",
   "metadata": {},
   "source": [
    "### 3.Setup LLM and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff447bc8-bc53-4643-96d2-3e0dadfe9b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                         \tID          \tSIZE  \tMODIFIED     \n",
      "command-r:35b-v0.1-q6_K      \tc46e949ec735\t28 GB \t3 days ago  \t\n",
      "llama2:13b-f16               \t18051f2e82e3\t26 GB \t2 weeks ago \t\n",
      "llama2:7b-f32                \t4901050728fc\t26 GB \t2 weeks ago \t\n",
      "llama2-chinese:13b-chat-fp16 \t3d4c5a00962c\t26 GB \t2 weeks ago \t\n",
      "llama2-chinese:7b-chat-fp16  \tb73150f2949c\t13 GB \t2 weeks ago \t\n",
      "llama3:70b-instruct-q4_0     \tbcfb190ca3a7\t39 GB \t38 hours ago\t\n",
      "llama3:8b-instruct-fp16      \tc1d0ea97005c\t16 GB \t39 hours ago\t\n",
      "llama3:8b-text-fp16          \tfc1ae0909d51\t16 GB \t39 hours ago\t\n",
      "llava:34b-v1.6-q6_K          \t8f572ea02185\t28 GB \t3 days ago  \t\n",
      "mistral:7b-instruct-v0.2-fp16\t094d67ff087c\t14 GB \t3 days ago  \t\n",
      "mixtral:latest               \t7708c059a8bb\t26 GB \t2 weeks ago \t\n",
      "mxbai-embed-large:latest     \t468836162de7\t669 MB\t11 days ago \t\n",
      "nomic-embed-text:latest      \t0a109f422b47\t274 MB\t2 weeks ago \t\n",
      "wizardlm2:7b-fp16            \ta34a3bbd552b\t14 GB \t4 days ago  \t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5aacd20b-157f-4441-88b8-b76e5ce6b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "# setup llm\n",
    "# local_llm = 'llama3:8b-instruct-fp16'\n",
    "# local_llm = 'command-r:35b-v0.1-q6_K'\n",
    "# local_llm = 'wizardlm2:7b-fp16'\n",
    "# local_llm = 'mistral:7b-instruct-v0.2-fp16'\n",
    "local_llm = 'mixtral:latest'\n",
    "\n",
    "llm = Ollama(model=local_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95feb79c-5fdf-4658-abad-dd07fd1c43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms.chatglm3 import ChatGLM3\n",
    "\n",
    "# llm = ChatGLM3(\n",
    "#     model='chatglm3-6b',\n",
    "#     endpoint_url='http://127.0.0.1:8000/v1/chat/completions',\n",
    "#     verbose=True\n",
    "# )\n",
    "# llm.invoke('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ea6ab88-cbaa-454d-be8e-baa1d2d38372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a1bdacf-66dd-4d6b-a4b7-aaf62697f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RAG prompt\n",
    "rag_prompt = ChatPromptTemplate(\n",
    "    input_variables=['context', 'question'],\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['context', 'question'],\n",
    "                # template=\"\"\"You answer questions about the contents of a transcribed audio file.\n",
    "                # Use only the provided audio file transcription as context to answer the question. \n",
    "                # Do not use any additional information.\n",
    "                # If you don't know the answer, just say that you don't know. Do not use external knowledge. \n",
    "                # Use three sentences maximum and keep the answer concise. \n",
    "                # Make sure to reference your sources with quotes of the provided context as citations.\n",
    "                # \\nQuestion: {question} \\nContext: {context} \\nAnswer:\n",
    "                # \"\"\",\n",
    "                template=\"\"\"你针对会议录音转的文字内容回答问题。\n",
    "                只利用录音转的文字内容作为上下文来回答问题。\n",
    "                不要使用任何其它额外信息。\n",
    "                如果你不知道答案，就回答不知道，不要使用外部知识。\n",
    "                用最多五句话来回答，并确保答案准确。\n",
    "                确保在答案中对上下文的源信息进行引用。\n",
    "                \\nQuestion: {question} \\nContext: {context} \\nAnswer:\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77e4d90a-dfff-4cc5-ab7b-5406e59b58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load qa chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm=llm, chain_type='stuff', prompt=rag_prompt, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87d18d-5122-48e3-995e-28ce97c09e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c24b27a-76b7-4c78-a576-831bb3b8e75a",
   "metadata": {},
   "source": [
    "### Query and Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40a46c27-f80e-4a22-a0e4-8481eb842b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a query\n",
    "query = '这次Performance review的rating是什么？'\n",
    "# query = '监管政策的解读'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "678f1852-c9fa-43c8-bd20-98494f4ae3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity search\n",
    "# docs = speech_vector.max_marginal_relevance_search(query, k=5, fetch_k=28, lambda_mult=0.5)\n",
    "docs = speech_vector.similarity_search(query, )\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a9a0970-159a-4ce8-9914-cf8f14887260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the self-evident propositions in the speech are:\n",
      " Based on the meeting recording transcript, the exact rating from the performance review was not explicitly stated. However, it was mentioned that there were improvements from December to January, with December having an amber rating in the performance monitoring dimension and January showing all green ratings, except for a failed PLA agreed service. Without specific reference to the rating, it can be inferred that the review result improved from December to January.\n"
     ]
    }
   ],
   "source": [
    "# using chain for the query\n",
    "response = chain.invoke(\n",
    "    input={'input_documents': docs, 'question': query}, \n",
    "    # return_only_outputs=True,\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "print(\"Based on the provided context, the self-evident propositions in the speech are:\")\n",
    "# print(\"\\n\".join(response[\"output_text\"]))\n",
    "print(response[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b62cdf7d-f116-48a6-af79-09c4b1a4efb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, the exact performance review rating is not explicitly mentioned. However, it's stated that there was an 'amber' rating in December, which was categorized under the 'performance monitoring' dimension. In January, the situation improved as everything was 'green', except for the PLA service that failed. So, without a clear rating for the performance review, I can only report the status of the 'performance monitoring' metric, which was 'amber' in December and not explicitly mentioned for January.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'input_documents': docs, 'question': query},)['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be17ef-d582-43a4-bdb8-5fbcb17f5680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49748615-284c-42bd-9592-7fe571fdaf96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97d17182-325b-462c-8ade-cc007780f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# setup llm\n",
    "local_llm = 'wizardlm2:7b-fp16'\n",
    "# local_llm = 'llama3:8b-instruct-fp16'\n",
    "llm = ChatOllama(model=local_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fbb39d3b-30f3-4187-a610-39238a88eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get retriever --> equvalent to vector search\n",
    "retriever = speech_vector.as_retriever(\n",
    "    search_type='similarity',  # similarity, mmr, similarity_score_threshold\n",
    "    search_kwargs={'k':5, },  # k, score_threshold\n",
    ")\n",
    "\n",
    "# check retriever\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef505d09-2a7a-43e4-94f4-76277e4950f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# Chain\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e9ea4c4-963f-4a8a-ad13-38e87a9dab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据会议录音转换的文字内容，Performance review的rating在1月份的评估中表现为全部green，即良好状态。在12月份的评估中，amber rating（黄色状态）被放置在performance monitoring（性能监控）的维度上。这说明在性能监控方面可能存在需要改进的地方。总的来说，这次的Performance review是为了评估外包服务的表现，并且提供了一个lesson learned，即在进行系统变更时需要更多地考虑到对下游周边系统的影响以及沟通。具体的rating metrics可以在相关文档中查看，其中包括多个维度的综合评估。在1月份的最新deck中，也有记录了这些问题作为problems需要解决。\n",
      "\n",
      "引用来源：提供的文档内容（页面内容1, 6, 1）。\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae77a89-da81-42ef-bcff-dd4e29710244",
   "metadata": {},
   "source": [
    "#### 2.4 Meeting Minutes Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc46f412-f6a2-4c6b-a7c1-fd8f1f0fab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(transcribe_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe788204-07f1-43b1-bcfb-9198eacdd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary prompt\n",
    "summary_prompt_template = \"\"\"Your goal is to summarize the meeting transcription that is given to you as the following:\n",
    "                \"{text}\"\n",
    "                The summarization of the meeting minutes shall limit to 2500 words.\n",
    "                Only output the summary without any additional text.\n",
    "                Focus on providing a summary in a structured format text of what subject reviewed and the action items out of it.\n",
    "                \"\"\"\n",
    "summary_prompt = PromptTemplate.from_template(summary_prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55774c7a-1cbc-45d0-893a-99d83894ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "docs = [Document(page_content=transcribe_text, metadata={\"source\": \"local\"})]\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "\n",
    "# Define StuffDocumentsChain\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "\n",
    "# print(stuff_chain.invoke(docs)['output_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb98df-9067-411e-8c84-74b88a9c2674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
